# AI Music Detection - Setup Guide

MusicTruth uses state-of-the-art Deep Learning models to identify if a track was generated by AI platforms like **Suno**, **Udio**, or **MusicGen**.

## Primary Detector: Hugging Face Transformers

The baseline detector is based on the `AI-Music-Detection/ai_music_detection_large_60s` model.

### Features
- **Automatic Lifecycle**: The model is automatically downloaded and cached from Hugging Face on the first run.
- **Robustness**: Specifically trained to distinguish between synthetic acoustic patterns and human compositions.
- **Hardware Acceleration**: Automatically uses **CUDA** (NVIDIA GPU) if available, otherwise falls back to CPU.

## Requirements

1. **PyTorch**: Required for model inference.
   ```bash
   pip install torch
   ```

2. **Transformers**: Required for the Hugging Face integration.
   ```bash
   pip install transformers
   ```

## Configuration

You can change the target model in your `.env` file:

```env
# Optional: Use a different HF model ID
AI_DETECTION_MODEL=AI-Music-Detection/ai_music_detection_large_60s
```

## How it works

1. When you select **Forensic** or **Deep** analysis, the `MusicAIDetector` is initialized.
2. It loads the weights into your local cache (typically `~/.cache/huggingface/hub`).
3. Audio is analyzed in 60-second segments to detect AI footprints.
4. A probability score (0-1) is returned.

## Interpretation of Results

- **90%+ (Critical)**: Strong match with known AI generator outputs. Likely Suno/Udio.
- **50-80% (Suspicious)**: Contains artifacts common in generative models.
- **Below 20%**: Likely authentic/human.
